# Neural Network from Scratch using NumPy ğŸ§ âœ¨

This project demonstrates how to build a simple feedforward neural network **from scratch** using just `NumPy`, with:

- Dense layers
- ReLU activation for hidden layers
- Softmax activation for output
- Categorical Cross-Entropy loss function

## ğŸ“Œ Key Concepts Covered
- Forward propagation with matrix math (`np.dot`)
- Activation functions: ReLU & Softmax
- One-hot encoded labels and sparse class indices
- Loss function: Categorical Cross-Entropy
- Shape compatibility and numpy broadcasting

## ğŸ› ï¸ Technologies Used
- Python
- NumPy
- Google Colab
- NNFS Dataset (`spiral_data`)

## ğŸš€ Run It Yourself
To run this notebook:

1. Open in Google Colab: [Open in Colab](https://colab.research.google.com/github/your-username/neural-network-from-scratch/blob/main/neural_network_from_scratch.ipynb)
2. Run all cells to see how the network is built and how predictions evolve.

## âœï¸ Author
Saptangshu Datta

---

â­ Star this repo if you found it helpful!
